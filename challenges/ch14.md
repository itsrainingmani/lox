# Chapter 14: Chunks of Bytecode | Challenges

1. Our encoding of line information is hilariously wasteful of memory. Given that a series of instructions often correspond to the same source line, a natural solution is something akin to run-length encoding of the line numbers.

Devise an encoding that compresses the line information for a series of instructions on the same line. Change `writeChunk()` to write this compressed form, and implement a `getLine()` function that, given the index of an instruction, determines the line where the instruction occurs.

_Hint: It’s not necessary for `getLine()` to be particularly efficient. Since it is called only when a runtime error occurs, it is well off the critical path where performance matters._

A Run-Length Encoding of Line information can look like this -

```c
typedef struct {
  int offset;
  int line;
} LineStart;
```

Each `LineStart` value marks the beginning of a new line and the corresponding byte offset of the first instruction of that line. My initial approach was to mark when a new line was encountered and maintain a count of how many instructions we saw on that line. But this format makes it easier to apply a binary search to find the line that a given instruction was on.

We maintain a separate dynamic array of `LineStart` and need to manage it's count and capacity accordingly. We de-couple the growth of `LineStart` from that of `Chunk` and add a new `LineStart` as follows -

```c
LineStart *lineStart = &chunk->lines[chunk->lineCount++];
lineStart->offset = chunk->count - 1;
lineStart->line = line;
```

In order to get the line an instruction is at, we use binary search to find the closest offset that is greater than the given instruction's offset

```c
int getLine(Chunk *chunk, int instrIndex) {
  int start = 0;
  int end = chunk->lineCount - 1;

  for (;;) {
    int mid = (start + end) / 2;
    LineStart *line = &chunk->lines[mid];
    if (instrIndex < line->offset) {
      end = mid - 1;
    } else if (mid == chunk->lineCount - 1 ||
               instrIndex < chunk->lines[mid + 1].offset) {
      return line->line;
    } else {
      start = mid + 1;
    }
  }
}
```

We can then use this function in `disassembleInstruction()` like so -

```c
int line = getLine(chunk, offset);

if (offset > 0 && line == getLine(chunk, offset - 1)) {
  printf("    | ");
} else {
  printf("%4d ", line);
}
```

2. Because `OP_CONSTANT` uses only a single byte for its operand, a chunk may only contain up to 256 different constants. That’s small enough that people writing real-world code will hit that limit. We could use two or more bytes to store the operand, but that makes every constant instruction take up more space. Most chunks won’t need that many unique constants, so that wastes space and sacrifices some locality in the common case to support the rare case.

To balance those two competing aims, many instruction sets feature multiple instructions that perform the same operation but with operands of different sizes. Leave our existing one-byte OP_CONSTANT instruction alone, and define a second `OP_CONSTANT_LONG` instruction. It stores the operand as a 24-bit number, which should be plenty.

Implement this function:

```c
void writeConstant(Chunk\* chunk, Value value, int line) {
// Implement me...
}
```

It adds value to chunk’s constant array and then writes an appropriate instruction to load the constant. Also add support to the disassembler for `OP_CONSTANT_LONG` instructions.

Defining two instructions seems to be the best of both worlds. What sacrifices, if any, does it force on us?

```c
void writeConstant(Chunk *chunk, Value value, int line) {
  int index = addConstant(chunk, value);
  if (index < 256) {
    writeChunk(chunk, OP_CONSTANT, line);
    writeChunk(chunk, (uint8_t)index, line);
  } else {
    writeChunk(chunk, OP_CONSTANT_LONG, line);
    writeChunk(chunk, (uint8_t)(index & 0xff), line);
    writeChunk(chunk, (uint8_t)((index >> 8) & 0xff), line);
    writeChunk(chunk, (uint8_t)((index >> 16) & 0xff), line);
  }
}
```

And in our VM, we need to load the index of our "long constant" so we can look it up in our chunk's value array. To do this, we make use of a macro that is similar to `READ_CONSTANT()`.

```c
#define READ_LONG_CONSTANT()                                                   \
  (vm.chunk->constants.values[(uint32_t)(READ_BYTE() | READ_BYTE() << 8 |      \
                                         READ_BYTE() << 16)])

// This expands to
(vm.chunk->constants
     .values[(uint32_t)((*vm.ip++) | (*vm.ip++) << 8 | (*vm.ip++) << 16)])
```

This now allows us to handle up-to 2^24 = 16777216 different constants (which is a lot).

3. Our `reallocate()` function relies on the C standard library for dynamic memory allocation and freeing. `malloc()` and `free()` aren’t magic. Find a couple of open source implementations of them and explain how they work. How do they keep track of which bytes are allocated and which are free? What is required to allocate a block of memory? Free it? How do they make that efficient? What do they do about fragmentation?

Hardcore mode: Implement `reallocate()` without calling `realloc()`, `malloc()`, or `free()`. You are allowed to call `malloc()` once, at the beginning of the interpreter’s execution, to allocate a single big block of memory, which your `reallocate()` function has access to. It parcels out blobs of memory from that single region, your own personal heap. It’s your job to define how it does that.
